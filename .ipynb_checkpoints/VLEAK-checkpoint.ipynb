{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a0e8ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "import snntorch as snn\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from IPython.display import clear_output, HTML, Video\n",
    "\n",
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn.functional import pad, softmax\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import tonic\n",
    "import random\n",
    "from tonic import DiskCachedDataset\n",
    "import tonic.transforms as transforms\n",
    "\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed = 0\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "else:\n",
    "    torch.manual_seed(seed)\n",
    "    device = \"cpu\"\n",
    "print(f\"Running on {device}\")\n",
    "\n",
    "#RUN ONCE\n",
    "#!echo '/data' >> .gitignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ecf7e1-eaba-4bc2-9629-cb7faa7b03a4",
   "metadata": {},
   "source": [
    "### Load DVSGesture data, Utilities functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0d8c9a6-e521-4bc0-99bf-b64224965629",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SpikeAnimation():\n",
    "    def __init__(self, num_plots, color_map = 'coolwarm', frames = None):\n",
    "        self.to_plot = []\n",
    "        self.sizes = []\n",
    "        self.ims = []\n",
    "        self.color_map = color_map\n",
    "        self.calc_frames = True\n",
    "        self.fig, self.axs = plt.subplots(1, num_plots)\n",
    "        if frames is not None:\n",
    "            self.frames = frames\n",
    "            self.calc_frames = False\n",
    "        return\n",
    "            \n",
    "                       \n",
    "    def add_to_plot(self, three_dim_tensor, size, title):\n",
    "        assert len(three_dim_tensor.shape) == 3, \"Not a three dimensional tensor\"\n",
    "        self.to_plot.append(three_dim_tensor.squeeze(1).detach().numpy())\n",
    "        self.axs[len(self.to_plot)-1].set_title(title)\n",
    "        self.sizes.append(size)\n",
    "        self.ims.append( self.axs[len(self.to_plot)-1].imshow(self.to_plot[-1][0].reshape(size), \n",
    "                                      cmap = self.color_map) )\n",
    "        return\n",
    "        \n",
    "    def blit(self, n):\n",
    "        for iii, image in enumerate(self.ims):\n",
    "            image.set_array(self.to_plot[iii][n].reshape(self.sizes[iii]))\n",
    "        return self.ims\n",
    "    \n",
    "    def show(self, return_obj=False):\n",
    "        assert len(self.to_plot) != 0, \"No spikes loaded\"\n",
    "        ani = matplotlib.animation.FuncAnimation(self.fig, self.blit, frames = self.frames)\n",
    "        if return_obj:\n",
    "            return ani\n",
    "        return HTML(ani.to_jshtml())\n",
    "\n",
    "def quick_animate(three_dim_tensor, frames, titles=None, return_obj=False,):\n",
    "    temp = SpikeAnimation(max(2, len(three_dim_tensor)), frames=frames)\n",
    "    titles = [\" \"]*len(three_dim_tensor) if titles is None else titles\n",
    "    for count, iii in enumerate(three_dim_tensor):\n",
    "        temp.add_to_plot(iii.cpu(), (iii.shape[-1], iii.shape[-2]), f\"{titles[count]}\")\n",
    "    return temp.show(return_obj)\n",
    "\n",
    "def add_to_class(Class):\n",
    "    \"\"\"Register functions as methods in created class.\"\"\"\n",
    "    def wrapper(obj):\n",
    "        setattr(Class, obj.__name__, obj)\n",
    "    return wrapper\n",
    "\n",
    "def pos_neg_to_frame(loader_tensor):\n",
    "    # combine positive and negative channels of neuromorphic dataset\n",
    "    return (loader_tensor[:,:,1]-loader_tensor[:,:,0]).movedim(0,1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3be4c8c3-0a37-478d-863a-8c2af603ac21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class snn_hmax(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.counter = 0\n",
    "        self.num_ker1 = 4\n",
    "        self.num_ker2 = 8\n",
    "        self.num_classes = 11\n",
    "        self.num_capsule_channels = 16\n",
    "        self.feature_connections = torch.randint(4, (self.num_capsule_channels,5))\n",
    "        self.stdp_inshallah = nn.Conv2d(in_channels=10, out_channels=self.num_capsule_channels, kernel_size=31, stride=1, padding=1, groups=1, bias=True)\n",
    "        self.s1 = nn.Conv2d(in_channels=1, out_channels=self.num_ker1, \n",
    "                                     kernel_size=3, stride=1, padding=0, groups=1, bias=True)\n",
    "        self.c1 = nn.MaxPool2d(kernel_size=2, stride=None, padding=0)\n",
    "        self.c2 = nn.MaxPool2d(kernel_size=2, stride=None, padding=0)\n",
    "        self.fully_connected1 = nn.Linear(8064, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fully_connected2 = nn.Linear(512, self.num_classes)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d4c0ecf-28b5-42fe-b9db-3ceccb4c6e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = tonic.datasets.DVSGesture(save_to='./data',\n",
    "                               train=True)\n",
    "sensor_size = tonic.datasets.DVSGesture.sensor_size\n",
    "\n",
    "frame_transform = transforms.Compose([transforms.CropTime(max=2_000_000),\n",
    "                                      transforms.Downsample(spatial_factor=0.5),\n",
    "                                      transforms.ToFrame(sensor_size=(64,64,2),\n",
    "                                                         time_window=10_000)\n",
    "                                     ])\n",
    "trainset = tonic.datasets.DVSGesture(save_to='./data', transform=frame_transform, train=True)\n",
    "testset = tonic.datasets.DVSGesture(save_to='./data', transform=frame_transform, train=False)\n",
    "\n",
    "random.seed(seed)\n",
    "batch_size = 1\n",
    "\n",
    "train_subsample_percent = 40\n",
    "test_subsample_percent = 40\n",
    "\n",
    "################# DELETE IF USING WHOLE SET\n",
    "train_subsample_idx = random.sample(range(0, len(trainset)), int(len(trainset)*train_subsample_percent//100))\n",
    "test_subsample_idx = random.sample(range(0, len(testset)), int(len(testset)*test_subsample_percent//100))\n",
    "trainset = Subset(trainset,  train_subsample_idx)\n",
    "testset= Subset(testset,  test_subsample_idx)\n",
    "##########################################\n",
    "\n",
    "cached_trainset = DiskCachedDataset(trainset, cache_path='./cache/DVSGesture/train')\n",
    "cached_testset = DiskCachedDataset(testset, cache_path='./cache/DVSGesture/test')\n",
    "\n",
    "cached_dataloader = DataLoader(cached_trainset, batch_size=batch_size)\n",
    "\n",
    "train_loader = DataLoader(cached_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=True), shuffle=True)\n",
    "test_loader = DataLoader(cached_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0639f64-f213-48fd-b173-f8537c9265db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = snn_hmax().to(device)\n",
    "#model = torch.load(\"model35.5.pt\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b29eb64-7773-414d-b696-43f374bb82b4",
   "metadata": {},
   "source": [
    "### Static model methods for step-by-step demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e8d30e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights_updates = []\n",
    "yy_record = torch.zeros(430,24-10, batch_size, 10, 31,31)\n",
    "\n",
    "@add_to_class(snn_hmax)        \n",
    "def forward(self, input_spikes, record=True):\n",
    "    \n",
    "    num_steps, bat_size= input_spikes.shape[0:2]\n",
    "    im_size=31\n",
    "    container = torch.zeros(num_steps-10, bat_size, self.num_capsule_channels, 6,6).to(device)\n",
    "    \n",
    "    for cap_chan in range(self.num_capsule_channels):\n",
    "        capsule = torch.zeros((bat_size,10,im_size,im_size))\n",
    "        for jjj, batch_step in enumerate(input_spikes):\n",
    "\n",
    "            s1_reduced = self.s1(batch_step.to(device)) \n",
    "            c1_reduced = self.c1(s1_reduced)\n",
    "            capsule = capsule.roll(-1,1)\n",
    "            chann = c1_reduced[:, self.feature_connections[cap_chan,(jjj%5)]]\n",
    "            capsule[:len(c1_reduced),-1] = chann\n",
    "            if jjj>10: #wait for capsule to fill up\n",
    "                if record:\n",
    "                    yy_record[self.counter, jjj-10, :len(c1_reduced)] = capsule\n",
    "\n",
    "                xx = self.stdp_inshallah(torch.softmax(capsule.to(device), dim=-1))\n",
    "                xx = self.c2(xx.reshape(len(xx),12,12))\n",
    "                #cond = (xx.mean((1,2))>xx.mean((0,1,2)))\n",
    "                #container[jjj, cond, cap_chan] = xx[cond]\n",
    "                container[jjj-10, :, cap_chan] = xx\n",
    "    if record:\n",
    "        self.counter = self.counter+1\n",
    "    container = container[(container.sum([1,2,3,4]).sort(descending=True)[1]).sort()[0]]\n",
    "    container = container.movedim(0,1)\n",
    "    out = container.reshape(container.size(0), -1).to(device)\n",
    "    out = model.fully_connected1(out)\n",
    "    out = model.relu(out)\n",
    "    out = model.fully_connected2(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "@add_to_class(snn_hmax)\n",
    "def __call__(self, input_spikes, **kwargs):\n",
    "    return self.forward(input_spikes, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199dc1e4-580d-452d-ad4d-5501c227a3d1",
   "metadata": {},
   "source": [
    "## Initial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e98420d0-7c47-4e05-b339-5f83e4246ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee13ce2a-c81d-4f86-9ef8-8a047c2c8e8e",
   "metadata": {},
   "source": [
    "Want to show relationship between weight updates and timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18e252ec-ffda-4871-97fe-6101338ebbd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6fb9c1d1b44c70917f7e6f3735fde9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/430 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3781e3a38f4b9181397ae9ce03af45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tonic/cached_dataset.py:137\u001b[0m, in \u001b[0;36mDiskCachedDataset.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     data, targets \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_disk_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mFileNotFoundError\u001b[39;00m, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m _:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tonic/cached_dataset.py:212\u001b[0m, in \u001b[0;36mload_from_disk_cache\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m    211\u001b[0m target_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, _list \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m], [data_list, target_list]):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    564\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    565\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    566\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 567\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:231\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    230\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 231\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = './cache/DVSGesture/test/9_0.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     31\u001b[0m true \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, (test_images, test_labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(test_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m==\u001b[39m num_evaluate:\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/notebook.py:254\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tonic/cached_dataset.py:144\u001b[0m, in \u001b[0;36mDiskCachedDataset.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mFileNotFoundError\u001b[39;00m, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m _:\n\u001b[1;32m    139\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in cache, generating it now\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    141\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    142\u001b[0m     )\n\u001b[0;32m--> 144\u001b[0m     data, targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    145\u001b[0m     save_to_disk_cache(\n\u001b[1;32m    146\u001b[0m         data, targets, file_path\u001b[38;5;241m=\u001b[39mfile_path, compress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompress\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m# format might change during save to hdf5, i.e. tensors -> np arrays\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# We load the sample here again to keep the output format consistent.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataset.py:295\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tonic/datasets/dvsgesture.py:102\u001b[0m, in \u001b[0;36mDVSGesture.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m        a tuple of (events, target) where target is the index of the target class.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     events \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     events[:, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m  \u001b[38;5;66;03m# convert from ms to us\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     events \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mrecfunctions\u001b[38;5;241m.\u001b[39munstructured_to_structured(events, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[1;32m    430\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/format.py:790\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    792\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[1;32m    802\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[1;32m    803\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "loss_hist = []\n",
    "#weights = []\n",
    "#weights = list(weights)\n",
    "# Outer training loop\n",
    "num_evaluate = 100\n",
    "switch_flag = False\n",
    "for epoch in range(num_epochs):\n",
    "    #Load in the data in batches using the train_loader object\n",
    "    for i, (images, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}\", position=0, leave=True)):  \n",
    "        labels = labels.to(device)\n",
    "        ims = pos_neg_to_frame(images)[50:(74-50)*3+50:3].to(device)\n",
    "        \n",
    "        w = model.stdp_inshallah.weight.clone().detach()\n",
    "        outputs = model(ims)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_hist.append(loss)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        weights_updates.append(model.stdp_inshallah.weight-w)\n",
    "            \n",
    "        if i == 0:\n",
    "            with torch.no_grad():\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                predictions = []\n",
    "                true = []\n",
    "                for j, (test_images, test_labels) in enumerate(tqdm(test_loader, desc=\"Testing\")):\n",
    "                    if j == num_evaluate:\n",
    "                        break\n",
    "                    ims = pos_neg_to_frame(test_images)[50:(74-50)*3+50:3].to(device)\n",
    "                    \n",
    "                    if switch_flag:\n",
    "                        ims = ims[:, (test_labels == 1) | (test_labels==2)]\n",
    "                        test_labels = test_labels[(test_labels == 1) | (test_labels==2)]\n",
    "                        if ims.shape[1] == 0:\n",
    "                            continue\n",
    "                    \n",
    "                    test_labels = test_labels.to(device)\n",
    "                    outputs = model(ims, record=False)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += test_labels.size(0)\n",
    "                    correct += (predicted == test_labels).sum().item()\n",
    "                    true.append(int(test_labels))\n",
    "                    predictions.append(int(predicted))\n",
    "\n",
    "                print(f\"Predicted: {predictions}\")\n",
    "                print(f\"Labels: {true}\")\n",
    "                    \n",
    "                print(f'Accuracy of the network: {100*correct/total} %')\n",
    "                \n",
    "    model.counter=0\n",
    "    weights_updates = torch.stack(weights_updates)\n",
    "    torch.save(weights_updates, f\"weight_delta{100*correct/total}.pt\")\n",
    "    torch.save(yy_record, f\"inputs{100*correct/total}.pt\")\n",
    "    weights_updates = []\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "    #torch.save(model, f\"model{100*correct/total}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79cee17-cb10-48a6-9e68-66906111a62f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
